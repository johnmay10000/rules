# Automatic Type & ADT Generation for Data Flows
## Claude's Pattern Guide for Type-First Development

This guide teaches Claude how to automatically generate appropriate types, ADTs (Algebraic Data Types), and functional wrappers for common data flow scenarios across different technology stacks.

---

## Core Principle: Type-First Data Flow

**Every data flow should automatically generate:**
1. **Domain Types** - What the data represents
2. **State ADTs** - Loading, success, error states
3. **Error Types** - Specific failure modes
4. **Validation Types** - Input/output boundaries
5. **Transformation Types** - Intermediate representations

---

## Table of Contents

1. [Polars DataFrames (Python)](#polars-dataframes-python)
2. [MLX Arrays (Python)](#mlx-arrays-python)
3. [Supabase Collections (TypeScript)](#supabase-collections-typescript)
4. [React UI Data (TypeScript)](#react-ui-data-typescript)
5. [Cross-System Data Flows](#cross-system-data-flows)
6. [Automatic Type Inference Patterns](#automatic-type-inference-patterns)

---

## Polars DataFrames (Python)

### When Claude Sees: Polars DataFrame Operations

**Trigger:** User mentions "polars", "dataframe", "csv", "parquet", "data processing"

**Claude Automatically Generates:**

```python
from dataclasses import dataclass
from typing import Literal
from returns.result import Result, Success, Failure
import polars as pl

# 1. Schema Types (from dataframe structure)
@dataclass(frozen=True)
class UserRecord:
    """Generated from polars schema"""
    user_id: int
    name: str
    email: str
    age: int
    created_at: str

# 2. Error Types (for operations that can fail)
@dataclass(frozen=True)
class DataFrameError:
    _tag: Literal['LoadError', 'ValidationError', 'TransformError', 'SchemaError']
    message: str
    details: dict | None = None

# 3. Validation Types
@dataclass(frozen=True)
class ValidatedUserRecord:
    """Post-validation type with stricter constraints"""
    user_id: int  # positive
    name: str     # non-empty
    email: str    # valid format
    age: int      # 0-120
    created_at: str  # valid ISO date

# 4. State ADTs for DataFrame operations
@dataclass(frozen=True)
class DataFrameState:
    """Represents current state of data processing"""
    _tag: Literal['Empty', 'Loading', 'Loaded', 'Transformed', 'Failed']
    df: pl.DataFrame | None = None
    error: DataFrameError | None = None
    row_count: int = 0

# 5. Functional wrappers for operations
def load_csv(path: str) -> Result[pl.DataFrame, DataFrameError]:
    """Load CSV with error handling"""
    try:
        df = pl.read_csv(path)
        return Success(df)
    except Exception as e:
        return Failure(DataFrameError(
            _tag='LoadError',
            message=str(e),
            details={'path': path}
        ))

def validate_schema(
    df: pl.DataFrame,
    expected_columns: list[str]
) -> Result[pl.DataFrame, DataFrameError]:
    """Validate dataframe has expected schema"""
    actual_columns = set(df.columns)
    expected_set = set(expected_columns)
    
    if not expected_set.issubset(actual_columns):
        missing = expected_set - actual_columns
        return Failure(DataFrameError(
            _tag='SchemaError',
            message=f"Missing columns: {missing}",
            details={'missing': list(missing)}
        ))
    
    return Success(df)

def validate_row(row: dict) -> Result[ValidatedUserRecord, DataFrameError]:
    """Validate individual row"""
    errors = []
    
    if row['user_id'] <= 0:
        errors.append('user_id must be positive')
    if not row['name'].strip():
        errors.append('name cannot be empty')
    if '@' not in row['email']:
        errors.append('invalid email format')
    if not (0 <= row['age'] <= 120):
        errors.append('age must be between 0 and 120')
    
    if errors:
        return Failure(DataFrameError(
            _tag='ValidationError',
            message='; '.join(errors),
            details={'row': row}
        ))
    
    return Success(ValidatedUserRecord(**row))

def transform_dataframe(
    df: pl.DataFrame,
    transformations: list[callable]
) -> Result[pl.DataFrame, DataFrameError]:
    """Apply transformations with error handling"""
    result = df
    for transform in transformations:
        try:
            result = transform(result)
        except Exception as e:
            return Failure(DataFrameError(
                _tag='TransformError',
                message=str(e),
                details={'transform': transform.__name__}
            ))
    return Success(result)

# 6. Complete pipeline using composition
from returns.pipeline import pipe

def process_user_data(path: str) -> Result[list[ValidatedUserRecord], DataFrameError]:
    """
    Complete data processing pipeline.
    Auto-generated by Claude based on requirements.
    """
    return pipe(
        load_csv(path),
        lambda r: r.bind(lambda df: validate_schema(
            df, 
            ['user_id', 'name', 'email', 'age', 'created_at']
        )),
        lambda r: r.bind(lambda df: transform_dataframe(df, [
            lambda d: d.with_columns(pl.col('email').str.to_lowercase()),
            lambda d: d.filter(pl.col('age') >= 18),
        ])),
        lambda r: r.bind(lambda df: Success(df.to_dicts())),
        lambda r: r.bind(lambda rows: traverse_result(rows, validate_row))
    )

# Helper for traversing with validation
def traverse_result(
    items: list[dict],
    f: callable
) -> Result[list[ValidatedUserRecord], DataFrameError]:
    """Validate all rows, fail fast on first error"""
    results = []
    for item in items:
        match f(item):
            case Success(value):
                results.append(value)
            case Failure(_) as err:
                return err
    return Success(results)
```

### Usage Pattern for Claude

When user says: *"Load user data from CSV, validate it, and filter for adults"*

Claude generates:
1. ✅ Schema types from expected CSV structure
2. ✅ Error ADTs for loading, validation, schema mismatches
3. ✅ Validation types with business rules
4. ✅ Result-wrapped operations
5. ✅ Composed pipeline

---

## MLX Arrays (Python)

### When Claude Sees: MLX/Array Operations

**Trigger:** "mlx", "neural network", "tensor", "array", "model", "training"

**Claude Automatically Generates:**

```python
from dataclasses import dataclass
from typing import Literal, TypeVar
from returns.result import Result, Success, Failure
import mlx.core as mx
import mlx.nn as nn

# 1. Tensor Shape Types
@dataclass(frozen=True)
class TensorShape:
    """Type-safe tensor shape representation"""
    batch: int
    height: int
    width: int
    channels: int
    
    def volume(self) -> int:
        return self.batch * self.height * self.width * self.channels
    
    def __str__(self) -> str:
        return f"({self.batch}, {self.height}, {self.width}, {self.channels})"

@dataclass(frozen=True)
class ModelConfig:
    """Model configuration with constraints"""
    input_shape: TensorShape
    hidden_dims: list[int]
    output_dim: int
    dropout: float  # 0.0 to 1.0
    learning_rate: float  # positive

# 2. Training State ADT
@dataclass(frozen=True)
class TrainingState:
    """Immutable training state"""
    epoch: int
    step: int
    weights: mx.array
    optimizer_state: dict
    loss: float
    metrics: dict[str, float]
    
    def next_epoch(self) -> 'TrainingState':
        return TrainingState(
            epoch=self.epoch + 1,
            step=self.step,
            weights=self.weights,
            optimizer_state=self.optimizer_state,
            loss=self.loss,
            metrics=self.metrics
        )

# 3. Error Types
@dataclass(frozen=True)
class ModelError:
    _tag: Literal[
        'ShapeMismatch',
        'InvalidConfig',
        'TrainingError',
        'LoadError',
        'GradientError'
    ]
    message: str
    details: dict | None = None

# 4. Data Types
@dataclass(frozen=True)
class Batch:
    """Type-safe batch representation"""
    inputs: mx.array  # shape: (batch_size, ...)
    targets: mx.array  # shape: (batch_size, num_classes)
    
    def validate_shapes(self, expected_input_shape: TensorShape) -> Result['Batch', ModelError]:
        """Validate batch has expected shapes"""
        if self.inputs.shape[1:] != tuple(expected_input_shape.height, 
                                          expected_input_shape.width, 
                                          expected_input_shape.channels):
            return Failure(ModelError(
                _tag='ShapeMismatch',
                message=f"Expected {expected_input_shape}, got {self.inputs.shape}",
                details={'expected': str(expected_input_shape), 'actual': str(self.inputs.shape)}
            ))
        return Success(self)

# 5. Validation Functions
def validate_config(config: ModelConfig) -> Result[ModelConfig, ModelError]:
    """Validate model configuration"""
    errors = []
    
    if config.dropout < 0 or config.dropout > 1:
        errors.append('dropout must be between 0 and 1')
    if config.learning_rate <= 0:
        errors.append('learning_rate must be positive')
    if not config.hidden_dims:
        errors.append('hidden_dims cannot be empty')
    if any(d <= 0 for d in config.hidden_dims):
        errors.append('all hidden dimensions must be positive')
    
    if errors:
        return Failure(ModelError(
            _tag='InvalidConfig',
            message='; '.join(errors),
            details={'config': str(config)}
        ))
    
    return Success(config)

# 6. Model Operations with Result types
def create_model(config: ModelConfig) -> Result[nn.Module, ModelError]:
    """Create model from validated config"""
    return validate_config(config).map(lambda cfg: build_model(cfg))

def forward_pass(
    model: nn.Module,
    batch: Batch
) -> Result[mx.array, ModelError]:
    """Type-safe forward pass"""
    try:
        logits = model(batch.inputs)
        return Success(logits)
    except Exception as e:
        return Failure(ModelError(
            _tag='TrainingError',
            message=f"Forward pass failed: {str(e)}"
        ))

def compute_loss(
    logits: mx.array,
    targets: mx.array
) -> Result[mx.array, ModelError]:
    """Compute loss with validation"""
    if logits.shape[0] != targets.shape[0]:
        return Failure(ModelError(
            _tag='ShapeMismatch',
            message='Batch size mismatch between logits and targets'
        ))
    
    try:
        loss = nn.losses.cross_entropy(logits, targets)
        return Success(loss)
    except Exception as e:
        return Failure(ModelError(
            _tag='TrainingError',
            message=f"Loss computation failed: {str(e)}"
        ))

# 7. Training Step Composition
from returns.pipeline import pipe
from returns.curry import curry

@curry
def train_step(
    model: nn.Module,
    optimizer: any,
    state: TrainingState,
    batch: Batch
) -> Result[TrainingState, ModelError]:
    """
    Single training step - composable and pure.
    Auto-generated by Claude.
    """
    def compute_grads_and_loss(validated_batch: Batch) -> Result[tuple[dict, float], ModelError]:
        loss_and_grad = nn.value_and_grad(model, lambda m, b: compute_loss(m(b.inputs), b.targets))
        try:
            loss_val, grads = loss_and_grad(model, validated_batch)
            return Success((grads, float(loss_val)))
        except Exception as e:
            return Failure(ModelError(
                _tag='GradientError',
                message=str(e)
            ))
    
    def update_model(grads_and_loss: tuple[dict, float]) -> TrainingState:
        grads, loss_val = grads_and_loss
        optimizer.update(model, grads)
        return TrainingState(
            epoch=state.epoch,
            step=state.step + 1,
            weights=model.parameters(),
            optimizer_state=optimizer.state,
            loss=loss_val,
            metrics={'loss': loss_val}
        )
    
    return pipe(
        batch.validate_shapes(model.input_shape),
        lambda r: r.bind(compute_grads_and_loss),
        lambda r: r.map(update_model)
    )

# 8. Complete Training Loop
def train_epoch(
    model: nn.Module,
    optimizer: any,
    initial_state: TrainingState,
    batches: list[Batch]
) -> Result[TrainingState, ModelError]:
    """
    Train for one epoch - functional and composable.
    Auto-generated based on requirements.
    """
    from functools import reduce
    
    def step_reducer(
        state_result: Result[TrainingState, ModelError],
        batch: Batch
    ) -> Result[TrainingState, ModelError]:
        return state_result.bind(
            lambda state: train_step(model, optimizer, state, batch)
        )
    
    return reduce(step_reducer, batches, Success(initial_state))
```

### Usage Pattern for Claude

When user says: *"Create a training pipeline for image classification with MLX"*

Claude generates:
1. ✅ TensorShape types for dimensions
2. ✅ ModelConfig with validation
3. ✅ TrainingState ADT (immutable)
4. ✅ Error types for each failure mode
5. ✅ Result-wrapped operations
6. ✅ Composed training pipeline

---

## Supabase Collections (TypeScript)

### When Claude Sees: Supabase Queries

**Trigger:** "supabase", "database", "query", "fetch", "insert", "update"

**Claude Automatically Generates:**

```typescript
import { createClient } from '@supabase/supabase-js'
import * as TE from 'fp-ts/TaskEither'
import * as E from 'fp-ts/Either'
import { pipe } from 'fp-ts/function'

// 1. Database Schema Types (from Supabase schema)
interface Database {
  public: {
    Tables: {
      users: {
        Row: {
          id: string
          email: string
          name: string
          age: number
          created_at: string
        }
        Insert: {
          email: string
          name: string
          age: number
        }
        Update: {
          email?: string
          name?: string
          age?: number
        }
      }
      posts: {
        Row: {
          id: string
          user_id: string
          title: string
          content: string
          published: boolean
          created_at: string
        }
        Insert: {
          user_id: string
          title: string
          content: string
          published?: boolean
        }
        Update: {
          title?: string
          content?: string
          published?: boolean
        }
      }
    }
  }
}

// 2. Domain Types (richer than database types)
interface User {
  readonly id: string
  readonly email: string
  readonly name: string
  readonly age: number
  readonly createdAt: Date
}

interface Post {
  readonly id: string
  readonly userId: string
  readonly title: string
  readonly content: string
  readonly published: boolean
  readonly createdAt: Date
}

interface UserWithPosts extends User {
  readonly posts: readonly Post[]
}

// 3. Error ADT
type DbError = 
  | { readonly _tag: 'QueryError'; readonly message: string; readonly code?: string }
  | { readonly _tag: 'NotFound'; readonly resource: string; readonly id: string }
  | { readonly _tag: 'ValidationError'; readonly errors: readonly string[] }
  | { readonly _tag: 'ConstraintViolation'; readonly constraint: string }
  | { readonly _tag: 'NetworkError'; readonly message: string }

// 4. Query State ADT
type QueryState<T> = 
  | { readonly _tag: 'Idle' }
  | { readonly _tag: 'Loading' }
  | { readonly _tag: 'Success'; readonly data: T }
  | { readonly _tag: 'Error'; readonly error: DbError }

// 5. Validation Types
interface ValidatedUserInput {
  readonly email: string  // validated format
  readonly name: string   // non-empty
  readonly age: number    // 0-120
}

// 6. Conversion Functions
const dbUserToDomain = (dbUser: Database['public']['Tables']['users']['Row']): User => ({
  id: dbUser.id,
  email: dbUser.email,
  name: dbUser.name,
  age: dbUser.age,
  createdAt: new Date(dbUser.created_at)
})

const dbPostToDomain = (dbPost: Database['public']['Tables']['posts']['Row']): Post => ({
  id: dbPost.id,
  userId: dbPost.user_id,
  title: dbPost.title,
  content: dbPost.content,
  published: dbPost.published,
  createdAt: new Date(dbPost.created_at)
})

// 7. Validation Functions
const validateEmail = (email: string): E.Either<DbError, string> =>
  email.includes('@') && email.includes('.')
    ? E.right(email)
    : E.left({
        _tag: 'ValidationError',
        errors: ['Invalid email format']
      })

const validateName = (name: string): E.Either<DbError, string> =>
  name.trim().length >= 2
    ? E.right(name)
    : E.left({
        _tag: 'ValidationError',
        errors: ['Name must be at least 2 characters']
      })

const validateAge = (age: number): E.Either<DbError, number> =>
  age >= 0 && age <= 120
    ? E.right(age)
    : E.left({
        _tag: 'ValidationError',
        errors: ['Age must be between 0 and 120']
      })

const validateUserInput = (
  input: Database['public']['Tables']['users']['Insert']
): E.Either<DbError, ValidatedUserInput> =>
  pipe(
    E.Do,
    E.apS('email', validateEmail(input.email)),
    E.apS('name', validateName(input.name)),
    E.apS('age', validateAge(input.age))
  )

// 8. CRUD Operations with TaskEither
const supabase = createClient<Database>(url, key)

const fetchUser = (id: string): TE.TaskEither<DbError, User> =>
  pipe(
    TE.tryCatch(
      () => supabase
        .from('users')
        .select('*')
        .eq('id', id)
        .single(),
      (error): DbError => ({
        _tag: 'QueryError',
        message: String(error)
      })
    ),
    TE.filterOrElse(
      (result) => result.data !== null,
      (): DbError => ({
        _tag: 'NotFound',
        resource: 'user',
        id
      })
    ),
    TE.map(result => dbUserToDomain(result.data!))
  )

const fetchUserPosts = (userId: string): TE.TaskEither<DbError, readonly Post[]> =>
  pipe(
    TE.tryCatch(
      () => supabase
        .from('posts')
        .select('*')
        .eq('user_id', userId)
        .order('created_at', { ascending: false }),
      (error): DbError => ({
        _tag: 'QueryError',
        message: String(error)
      })
    ),
    TE.map(result => (result.data || []).map(dbPostToDomain))
  )

const createUser = (
  input: Database['public']['Tables']['users']['Insert']
): TE.TaskEither<DbError, User> =>
  pipe(
    TE.fromEither(validateUserInput(input)),
    TE.flatMap((validated) =>
      TE.tryCatch(
        () => supabase
          .from('users')
          .insert({
            email: validated.email,
            name: validated.name,
            age: validated.age
          })
          .select()
          .single(),
        (error): DbError => {
          const err = error as any
          if (err.code === '23505') {  // unique violation
            return {
              _tag: 'ConstraintViolation',
              constraint: 'unique_email'
            }
          }
          return {
            _tag: 'QueryError',
            message: String(error)
          }
        }
      )
    ),
    TE.map(result => dbUserToDomain(result.data!))
  )

// 9. Complex Queries with Composition
const fetchUserWithPosts = (id: string): TE.TaskEither<DbError, UserWithPosts> =>
  pipe(
    fetchUser(id),
    TE.flatMap(user =>
      pipe(
        fetchUserPosts(user.id),
        TE.map(posts => ({
          ...user,
          posts
        }))
      )
    )
  )

// 10. Batch Operations with Traverse
import * as A from 'fp-ts/Array'

const fetchMultipleUsers = (
  ids: readonly string[]
): TE.TaskEither<DbError, readonly User[]> =>
  A.traverse(TE.ApplicativePar)(fetchUser)(ids)

// 11. Filtering with Type-Safe Predicates
interface UserFilter {
  readonly minAge?: number
  readonly maxAge?: number
  readonly emailDomain?: string
}

const fetchFilteredUsers = (
  filter: UserFilter
): TE.TaskEither<DbError, readonly User[]> =>
  pipe(
    TE.tryCatch(
      () => {
        let query = supabase.from('users').select('*')
        
        if (filter.minAge !== undefined) {
          query = query.gte('age', filter.minAge)
        }
        if (filter.maxAge !== undefined) {
          query = query.lte('age', filter.maxAge)
        }
        if (filter.emailDomain) {
          query = query.ilike('email', `%@${filter.emailDomain}`)
        }
        
        return query
      },
      (error): DbError => ({
        _tag: 'QueryError',
        message: String(error)
      })
    ),
    TE.map(result => (result.data || []).map(dbUserToDomain))
  )
```

### Usage Pattern for Claude

When user says: *"Fetch users from Supabase and filter by age"*

Claude generates:
1. ✅ Database schema types from Supabase
2. ✅ Domain types (richer than DB types)
3. ✅ Error ADT for all failure modes
4. ✅ QueryState ADT for UI state management
5. ✅ Validation functions with Either
6. ✅ TaskEither-wrapped async operations
7. ✅ Type-safe filters and predicates

---

## React UI Data (TypeScript)

### When Claude Sees: React/UI Data Flow

**Trigger:** "react", "component", "ui", "frontend", "display", "filter"

**Claude Automatically Generates:**

```typescript
import { useEffect, useState } from 'react'
import * as TE from 'fp-ts/TaskEither'
import { pipe } from 'fp-ts/function'

// 1. Remote Data ADT (for async data)
type RemoteData<E, A> =
  | { readonly _tag: 'NotAsked' }
  | { readonly _tag: 'Loading' }
  | { readonly _tag: 'Failure'; readonly error: E }
  | { readonly _tag: 'Success'; readonly data: A }

// Helper constructors
const notAsked = <E, A>(): RemoteData<E, A> => ({ _tag: 'NotAsked' })
const loading = <E, A>(): RemoteData<E, A> => ({ _tag: 'Loading' })
const failure = <E, A>(error: E): RemoteData<E, A> => ({ _tag: 'Failure', error })
const success = <E, A>(data: A): RemoteData<E, A> => ({ _tag: 'Success', data })

// 2. UI State ADT
interface UserListState {
  readonly users: RemoteData<DbError, readonly User[]>
  readonly filters: UserFilter
  readonly selectedUser: RemoteData<DbError, UserWithPosts> | null
}

// 3. UI Actions (for state updates)
type UserListAction =
  | { readonly type: 'FETCH_USERS_START' }
  | { readonly type: 'FETCH_USERS_SUCCESS'; readonly users: readonly User[] }
  | { readonly type: 'FETCH_USERS_FAILURE'; readonly error: DbError }
  | { readonly type: 'UPDATE_FILTERS'; readonly filters: UserFilter }
  | { readonly type: 'SELECT_USER'; readonly userId: string }
  | { readonly type: 'CLEAR_SELECTION' }

// 4. Derived Data Types
interface FilteredUserList {
  readonly allUsers: readonly User[]
  readonly filteredUsers: readonly User[]
  readonly filterCount: number
}

// 5. UI-Specific Validation
interface UserFormInput {
  readonly email: string
  readonly name: string
  readonly age: string  // string from input
}

interface UserFormErrors {
  readonly email?: string
  readonly name?: string
  readonly age?: string
}

const validateUserForm = (
  input: UserFormInput
): E.Either<UserFormErrors, ValidatedUserInput> => {
  const errors: UserFormErrors = {}
  
  // Validate email
  if (!input.email.includes('@')) {
    errors.email = 'Invalid email format'
  }
  
  // Validate name
  if (input.name.trim().length < 2) {
    errors.name = 'Name must be at least 2 characters'
  }
  
  // Validate age
  const age = parseInt(input.age, 10)
  if (isNaN(age) || age < 0 || age > 120) {
    errors.age = 'Age must be between 0 and 120'
  }
  
  if (Object.keys(errors).length > 0) {
    return E.left(errors)
  }
  
  return E.right({
    email: input.email,
    name: input.name,
    age
  })
}

// 6. Filter Logic (Pure Functions)
const applyUserFilters = (
  users: readonly User[],
  filters: UserFilter
): readonly User[] => {
  let filtered = [...users]
  
  if (filters.minAge !== undefined) {
    filtered = filtered.filter(u => u.age >= filters.minAge!)
  }
  
  if (filters.maxAge !== undefined) {
    filtered = filtered.filter(u => u.age <= filters.maxAge!)
  }
  
  if (filters.emailDomain) {
    filtered = filtered.filter(u => 
      u.email.endsWith(`@${filters.emailDomain}`)
    )
  }
  
  return filtered
}

// 7. React Hook for Data Fetching
const useUsers = () => {
  const [state, setState] = useState<UserListState>({
    users: notAsked(),
    filters: {},
    selectedUser: null
  })
  
  const fetchUsers = () => {
    setState(prev => ({
      ...prev,
      users: loading()
    }))
    
    pipe(
      fetchFilteredUsers(state.filters),
      TE.match(
        (error) => setState(prev => ({
          ...prev,
          users: failure(error)
        })),
        (users) => setState(prev => ({
          ...prev,
          users: success(users)
        }))
      )
    )()
  }
  
  const updateFilters = (filters: UserFilter) => {
    setState(prev => ({
      ...prev,
      filters
    }))
  }
  
  const selectUser = (userId: string) => {
    setState(prev => ({
      ...prev,
      selectedUser: loading()
    }))
    
    pipe(
      fetchUserWithPosts(userId),
      TE.match(
        (error) => setState(prev => ({
          ...prev,
          selectedUser: failure(error)
        })),
        (user) => setState(prev => ({
          ...prev,
          selectedUser: success(user)
        }))
      )
    )()
  }
  
  return {
    state,
    fetchUsers,
    updateFilters,
    selectUser
  }
}

// 8. Pattern Matching for Rendering
const matchRemoteData = <E, A, B>(
  rd: RemoteData<E, A>,
  patterns: {
    notAsked: () => B
    loading: () => B
    failure: (error: E) => B
    success: (data: A) => B
  }
): B => {
  switch (rd._tag) {
    case 'NotAsked':
      return patterns.notAsked()
    case 'Loading':
      return patterns.loading()
    case 'Failure':
      return patterns.failure(rd.error)
    case 'Success':
      return patterns.success(rd.data)
  }
}

// 9. React Component with Generated Types
const UserList: React.FC = () => {
  const { state, fetchUsers, updateFilters, selectUser } = useUsers()
  
  useEffect(() => {
    fetchUsers()
  }, [state.filters])
  
  return (
    <div>
      <h1>Users</h1>
      
      {/* Filter UI */}
      <UserFilters
        filters={state.filters}
        onFiltersChange={updateFilters}
      />
      
      {/* User List with Pattern Matching */}
      {matchRemoteData(state.users, {
        notAsked: () => (
          <button onClick={fetchUsers}>Load Users</button>
        ),
        loading: () => (
          <div>Loading users...</div>
        ),
        failure: (error) => (
          <div className="error">
            <h3>Error: {error._tag}</h3>
            <p>{error.message || 'An error occurred'}</p>
            <button onClick={fetchUsers}>Retry</button>
          </div>
        ),
        success: (users) => {
          const filtered = applyUserFilters(users, state.filters)
          
          return (
            <div>
              <p>
                Showing {filtered.length} of {users.length} users
              </p>
              <ul>
                {filtered.map(user => (
                  <li key={user.id} onClick={() => selectUser(user.id)}>
                    {user.name} ({user.age}) - {user.email}
                  </li>
                ))}
              </ul>
            </div>
          )
        }
      })}
      
      {/* Selected User Detail */}
      {state.selectedUser && matchRemoteData(state.selectedUser, {
        notAsked: () => null,
        loading: () => <div>Loading user details...</div>,
        failure: (error) => <div>Error loading user: {error.message}</div>,
        success: (user) => (
          <div>
            <h2>{user.name}</h2>
            <p>Posts: {user.posts.length}</p>
            <ul>
              {user.posts.map(post => (
                <li key={post.id}>{post.title}</li>
              ))}
            </ul>
          </div>
        )
      })}
    </div>
  )
}

// 10. Form Component with Validation
const UserForm: React.FC<{
  onSubmit: (user: ValidatedUserInput) => void
}> = ({ onSubmit }) => {
  const [input, setInput] = useState<UserFormInput>({
    email: '',
    name: '',
    age: ''
  })
  const [errors, setErrors] = useState<UserFormErrors>({})
  
  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault()
    
    pipe(
      validateUserForm(input),
      E.match(
        (validationErrors) => setErrors(validationErrors),
        (validated) => {
          onSubmit(validated)
          setInput({ email: '', name: '', age: '' })
          setErrors({})
        }
      )
    )
  }
  
  return (
    <form onSubmit={handleSubmit}>
      <div>
        <label>Email</label>
        <input
          type="email"
          value={input.email}
          onChange={e => setInput({ ...input, email: e.target.value })}
        />
        {errors.email && <span className="error">{errors.email}</span>}
      </div>
      
      <div>
        <label>Name</label>
        <input
          value={input.name}
          onChange={e => setInput({ ...input, name: e.target.value })}
        />
        {errors.name && <span className="error">{errors.name}</span>}
      </div>
      
      <div>
        <label>Age</label>
        <input
          type="number"
          value={input.age}
          onChange={e => setInput({ ...input, age: e.target.value })}
        />
        {errors.age && <span className="error">{errors.age}</span>}
      </div>
      
      <button type="submit">Create User</button>
    </form>
  )
}
```

### Usage Pattern for Claude

When user says: *"Create a React component to display and filter users from Supabase"*

Claude generates:
1. ✅ RemoteData ADT for async state
2. ✅ UI state types with filters
3. ✅ Action types for state updates
4. ✅ Form validation with Either
5. ✅ Pure filter functions
6. ✅ Pattern matching for rendering
7. ✅ Type-safe hooks

---

## Cross-System Data Flows

### Example: End-to-End Type Flow

**Scenario:** "Load CSV data, process with Polars, train MLX model, save to Supabase, display in React"

**Claude Automatically Generates:**

```python
# Python Backend: Data Processing
from dataclasses import dataclass
from typing import Literal
from returns.result import Result
import polars as pl
import mlx.core as mx

# 1. Source Data Types
@dataclass(frozen=True)
class RawSalesRecord:
    """CSV input schema"""
    date: str
    product_id: str
    quantity: int
    price: float
    region: str

# 2. Processed Data Types
@dataclass(frozen=True)
class ProcessedSalesData:
    """After cleaning and feature engineering"""
    timestamp: int
    product_embedding: list[float]
    quantity_normalized: float
    price_normalized: float
    region_encoded: int

# 3. Model Types
@dataclass(frozen=True)
class SalesPrediction:
    """Model output"""
    product_id: str
    predicted_quantity: float
    confidence: float
    model_version: str

# 4. Database Output Types
@dataclass(frozen=True)
class PredictionRecord:
    """Format for Supabase insertion"""
    product_id: str
    prediction_date: str
    predicted_quantity: float
    confidence: float
    model_version: str
    created_at: str

# 5. API Response Type
@dataclass(frozen=True)
class PredictionResponse:
    """API endpoint response"""
    predictions: list[PredictionRecord]
    metadata: dict
    
# Complete Pipeline
def process_and_predict(
    csv_path: str
) -> Result[PredictionResponse, ProcessingError]:
    return pipe(
        load_csv(csv_path),
        lambda r: r.bind(validate_sales_schema),
        lambda r: r.map(clean_data),
        lambda r: r.map(engineer_features),
        lambda r: r.bind(run_model_inference),
        lambda r: r.bind(save_to_supabase),
        lambda r: r.map(format_api_response)
    )
```

```typescript
// TypeScript Frontend: Display Predictions

// 1. API Types (match Python output)
interface PredictionRecord {
  readonly product_id: string
  readonly prediction_date: string
  readonly predicted_quantity: number
  readonly confidence: number
  readonly model_version: string
  readonly created_at: string
}

interface PredictionResponse {
  readonly predictions: readonly PredictionRecord[]
  readonly metadata: {
    readonly total: number
    readonly model_version: string
    readonly generated_at: string
  }
}

// 2. UI Domain Types
interface DisplayPrediction {
  readonly productId: string
  readonly predictedQuantity: number
  readonly confidence: number
  readonly date: Date
  readonly confidenceLevel: 'high' | 'medium' | 'low'
}

// 3. Transform API to UI types
const apiToDisplayPrediction = (
  record: PredictionRecord
): DisplayPrediction => ({
  productId: record.product_id,
  predictedQuantity: record.predicted_quantity,
  confidence: record.confidence,
  date: new Date(record.prediction_date),
  confidenceLevel: record.confidence > 0.8 
    ? 'high' 
    : record.confidence > 0.5 
    ? 'medium' 
    : 'low'
})

// 4. Fetch with TaskEither
const fetchPredictions = (): TE.TaskEither<ApiError, PredictionResponse> =>
  pipe(
    TE.tryCatch(
      () => fetch('/api/predictions').then(r => r.json()),
      (error): ApiError => ({
        _tag: 'NetworkError',
        message: String(error)
      })
    )
  )

// 5. UI State
type PredictionState = RemoteData<ApiError, readonly DisplayPrediction[]>

// 6. Component
const PredictionDashboard: React.FC = () => {
  const [state, setState] = useState<PredictionState>(notAsked())
  
  const loadPredictions = () => {
    setState(loading())
    
    pipe(
      fetchPredictions(),
      TE.map(response => 
        response.predictions.map(apiToDisplayPrediction)
      ),
      TE.match(
        (error) => setState(failure(error)),
        (predictions) => setState(success(predictions))
      )
    )()
  }
  
  return matchRemoteData(state, {
    notAsked: () => <button onClick={loadPredictions}>Load</button>,
    loading: () => <div>Loading predictions...</div>,
    failure: (error) => <div>Error: {error.message}</div>,
    success: (predictions) => (
      <div>
        <h1>Sales Predictions</h1>
        <table>
          {predictions.map(p => (
            <tr key={p.productId}>
              <td>{p.productId}</td>
              <td>{p.predictedQuantity.toFixed(2)}</td>
              <td className={`confidence-${p.confidenceLevel}`}>
                {(p.confidence * 100).toFixed(1)}%
              </td>
            </tr>
          ))}
        </table>
      </div>
    )
  })
}
```

---

## Automatic Type Inference Patterns

### Pattern Recognition Rules for Claude

Claude should automatically generate types when it sees:

| User Input Trigger | Auto-Generate |
|-------------------|---------------|
| "load CSV/DataFrame" | Schema types, Error ADT, Result wrapper |
| "query database/Supabase" | Database types, Domain types, DbError ADT, TaskEither |
| "MLX/tensor/model" | Shape types, Config types, Training state, ModelError |
| "React component/display" | RemoteData ADT, UI state, Filter types, Form validation |
| "validate input" | Validation types, Error collection, Either |
| "process batch" | Batch types, Processing state, Traverse pattern |
| "API endpoint" | Request/Response types, Error ADT, TaskEither handler |
| "state machine" | State ADT, Action types, Reducer |

### Type Generation Checklist

For every data flow, Claude generates:

- [ ] **Domain types** - What the data represents
- [ ] **State ADTs** - Current state of operations
- [ ] **Error types** - Specific failure modes
- [ ] **Validation types** - Input/output boundaries
- [ ] **Transformation types** - Intermediate steps
- [ ] **Wrapper types** - Result/Either/TaskEither
- [ ] **Helper functions** - Conversion, validation, pattern matching

---

## Summary

### Core Philosophy

**Every piece of data flowing through the system should have:**
1. A clear type representing its structure
2. An ADT representing its possible states
3. Error types for what can go wrong
4. Functional wrappers (Result/Either/TaskEither)
5. Validation at boundaries
6. Pure transformation functions

### Benefits

✅ **Type Safety** - Compiler catches errors
✅ **Composability** - Small functions compose to complex behavior
✅ **Testability** - Pure functions are easy to test
✅ **Maintainability** - Types document intent
✅ **Refactorability** - Safe to change code
✅ **Error Handling** - Explicit and exhaustive

### Claude's Role

When generating code, Claude should:
1. **Infer** what data types are needed from context
2. **Generate** appropriate ADTs and error types
3. **Wrap** operations in Result/Either/TaskEither
4. **Compose** using functional patterns
5. **Validate** at system boundaries
6. **Document** types and their invariants

---

*This guide enables Claude to automatically generate type-first, functional code for any data flow scenario, ensuring type safety, composability, and maintainability across Python and TypeScript stacks.*
